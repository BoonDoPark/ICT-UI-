{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML parsing을 위한 모듈\n",
    "- parsing : html 문서내에서 원하는 값만 추출하는 것\n",
    "- BeautifulSoup의 메인 패키지인 bs패키지에서 BeautifulSoup import\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/   \n",
    "- 서버에서 가져온 html을 xml구조로 변환하여 읽으면 트리 형태로 스크래핑 가능 -> 파서(parser) 필요\n",
    "- 파서 : lxml(주로 이용되는 패키지),html.parser,lxml-xml, html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "  <head>\n",
    "    <title>BeautifulSoup test</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div id='upper' class='test' custom='good'>\n",
    "      <h3 title='Good Content Title'>Contents Title</h3>\n",
    "      <p>Test contents</p>\n",
    "    </div>\n",
    "    <div id='lower' class='test' custom='nice'>\n",
    "      <p>Test Test Test 1</p>\n",
    "      <p>Test Test Test 2</p>\n",
    "      <p>Test Test Test 3</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BeautifulSoup 모듈 기본 사용법\n",
    "### 1.1 객체생성\n",
    "- BeautifulSoup(파싱할 HTML문서, 파싱에 사용할 파서(구문분석기))\n",
    "- HTML 문서에 대한 파싱이 끝나면 트리구조 형식의 DOM객체 생성\n",
    "- 객체의 태그 접근 방법 : 태그명을 .연산자와 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<p>Test contents</p>\n",
      "</div>\n",
      "\n",
      "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<p>Test contents</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html,'lxml')\n",
    "print(soup.body.div)\n",
    "print()\n",
    "print(soup.div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 태그의 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div\n",
      "{'id': 'upper', 'class': ['test'], 'custom': 'good'}\n",
      "upper\n",
      "\n",
      "Contents Title\n",
      "Test contents\n",
      "\n",
      "Test contents\n"
     ]
    }
   ],
   "source": [
    "print(soup.div.name)\n",
    "print(soup.div.attrs)\n",
    "print(soup.div['id'])\n",
    "print(soup.div.get_text())\n",
    "print(soup.p.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 태그로부터 다른 태그로 이동\n",
    "- bs.태그명.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>\n",
       "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       "<p>Test Test Test 1</p>\n",
       "<p>Test Test Test 2</p>\n",
       "<p>Test Test Test 3</p>\n",
       "</div>\n",
       "</body>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.div.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs.태그명.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <h3 title=\"Good Content Title\">Contents Title</h3>,\n",
       " '\\n',\n",
       " <p>Test contents</p>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.div.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs.태그명.next_sibling : 다음 형제태그로 이동\n",
    "- bs.태그명.previous_sibling : 앞 형제태그로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
      "<p>Test Test Test 1</p>\n",
      "<p>Test Test Test 2</p>\n",
      "<p>Test Test Test 3</p>\n",
      "</div>\n",
      "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<p>Test contents</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "tag2 = soup.div.next_sibling.next_sibling\n",
    "print(tag2)\n",
    "print(tag2.previous_sibling.previous_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. find()\n",
    " - 특정 html tag를 검색\n",
    " - 검색 조건을 명시하여 찾고자하는 tag를 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('h3'))\n",
    "print(soup.h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Test contents</p>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- div의 lower를 찾고 싶다면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       "<p>Test Test Test 1</p>\n",
       "<p>Test Test Test 2</p>\n",
       "<p>Test Test Test 3</p>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', custom='nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       "<p>Test Test Test 1</p>\n",
       "<p>Test Test Test 2</p>\n",
       "<p>Test Test Test 3</p>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', id='lower')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class는 키워드라서 사용할 수 없다. class_로 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-29800156a644>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-29800156a644>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    soup.find('div', class='test')\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "soup.find('div', class='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', class_='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "<p>Test contents</p>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
       "<p>Test contents</p>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs = {'id':'upper', 'class': 'test'}\n",
    "print(soup.find('div', attrs=attrs))\n",
    "soup.find('div', attrs={'id':'upper'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. find_all()\n",
    " - find가 조건에 만족하는 하나의 tag만 검색한다면, find_all은 조건에 맞는 모든 tag를 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       " <h3 title=\"Good Content Title\">Contents Title</h3>\n",
       " <p>Test contents</p>\n",
       " </div>,\n",
       " <div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       " <p>Test Test Test 1</p>\n",
       " <p>Test Test Test 2</p>\n",
       " <p>Test Test Test 3</p>\n",
       " </div>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Test contents</p>,\n",
       " <p>Test Test Test 1</p>,\n",
       " <p>Test Test Test 2</p>,\n",
       " <p>Test Test Test 3</p>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"test\" custom=\"good\" id=\"upper\">\n",
       " <h3 title=\"Good Content Title\">Contents Title</h3>\n",
       " <p>Test contents</p>\n",
       " </div>,\n",
       " <div class=\"test\" custom=\"nice\" id=\"lower\">\n",
       " <p>Test Test Test 1</p>\n",
       " <p>Test Test Test 2</p>\n",
       " <p>Test Test Test 3</p>\n",
       " </div>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', class_='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. get_text()\n",
    " - tag안의 value를 추출\n",
    " - 우리가 얻고자 하는 대부분의 정보는 value에 존재\n",
    " - 부모tag의 경우, 모든 자식 tag의 value를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n",
      "Contents Title\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('h3')\n",
    "print(tag)\n",
    "print(tag.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Test contents</p>\n",
      "Test contents\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('p')\n",
    "print(tag)\n",
    "print(tag.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"test\" custom=\"nice\" id=\"lower\">\n",
      "<p>Test Test Test 1</p>\n",
      "<p>Test Test Test 2</p>\n",
      "<p>Test Test Test 3</p>\n",
      "</div>\n",
      "\n",
      "Test Test Test 1\n",
      "Test Test Test 2\n",
      "Test Test Test 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('div', id='lower')\n",
    "print(tag)\n",
    "print(tag.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. attribute 값 추출하기\n",
    " - 경우에 따라 추출하고자 하는 값이 attribute에도 존재함\n",
    " - 이 경우에는 검색한 tag에 attribute 이름을 [ ]연산을 통해 추출가능\n",
    " - 예) div.find('h3')['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 title=\"Good Content Title\">Contents Title</h3>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Good Content Title'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = soup.find('h3')\n",
    "print(tag)\n",
    "tag['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. id, class 속성으로 tag 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다음 뉴스 데이터 추출**\n",
    "- 뉴스기사에서 제목, 작성자, 작성일 추출\n",
    "- tag를 추출할때는 가장 그 tag를 쉽게 특정할 수 있는 속성을 사용\n",
    "- id의 경우 원칙적으로 한 html 문서 내에서 유일\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://news.v.daum.net/v/20210829114520406'\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. class 속성으로 tag 찾기\n",
    " - 타이틀\n",
    " - 작성자, 작성일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미군 등 철수시한 임박 카불공항..탈레반 \"넘겨받을 준비\"'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find('h3', class_='tit_view')\n",
    "title.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"txt_info\">성혜미</span>\n",
      "<span class=\"txt_info\">입력 <span class=\"num_date\">2021. 08. 29. 11:45</span></span>\n"
     ]
    }
   ],
   "source": [
    "# 방법1 : 전체 문서에서 찾는 법\n",
    "print(soup.find_all('span', class_=\"txt_info\")[0])\n",
    "print(soup.find_all('span', class_=\"txt_info\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성혜미\n",
      "2021. 08. 29\n"
     ]
    }
   ],
   "source": [
    "# 방법2 : 부모클래스를 찾고 info_view내에서 찾는다.\n",
    "# 범위를 줄여가면서 찾는 방법\n",
    "\n",
    "info = soup.find('span', class_=\"info_view\")\n",
    "\n",
    "print(info.find('span', class_='txt_info').get_text())\n",
    "print(info.find('span', class_='num_date').get_text()[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 id 속성으로 tag 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(자카르타=연합뉴스) 성혜미 특파원 = 미군 등 외국군과 조력자의 아프가니스탄 철수시한이 이틀 앞으로 다가온 29일 탈레반은 수도 카불공항 주변을 거의 봉쇄하고 넘겨받을 준비를 하고 있다.\n",
      "영국군을 태운 마지막 수송기가 카불공항에서 이륙하는 등 대다수 국가가 아프간 대피 작전을 속속 마무리했다.\n",
      "\n",
      "영국 국방부는 전날 \"영국군을 태운 마지막 수송기가 카불을 떠났다\"며 사진과 함께 트윗을 올렸다.\n",
      "독일, 이탈리아, 스위스, 스웨덴, 핀란드 등 유럽국가들은 27∼28일 대부분 대피 작전 종료를 선언했다.\n",
      "이들 국가는 아프간에 남은 자국민과 조력자에 대해 \"모두 데려오지 못해 유감\"이라며 대피 작전 종료 이후에도 육로를 통한 탈출 지원 등 노력을 계속하겠다는 입장이다.\n",
      "특히 에마뉘엘 마크롱 프랑스 대통령은 카불에 유엔이 통제하는 '안전지대'(safe zone)를 조성하자며, 30일 예정된 유엔안보리 긴급회의에 영국과 함께 이 방안을 제안할 계획이라고 밝혔다.\n",
      "마크롱 대통령은 \"카불에 안전지대를 만들면 인도주의적 활동을 지속할 수 있다. 안전지대는 유엔이 비상시에 움직일 수 있는 틀을 마련해 줄 것\"이라고 말했다.\n",
      "\n",
      "카불공항은 지난 26일 발생한 이슬람국가(IS)의 자살폭탄테러 사건 이후 현지인들의 접근이 거의 차단된 상황이다.\n",
      "이전에는 수송기 탑승 명단에 오른 현지인 조력자뿐만 아니라, 수많은 현지인이 공항 담벼락 주변에 장사진을 치고 \"우리도 태워달라\"며 실낱같은 희망을 품고 기다렸다.\n",
      "하지만, 26일 카불공항 외곽에서 대형 테러가 발생해 170명 이상이 숨지고, 1천300명 이상이 다치자 탈레반은 공항 경계를 강화한다며 장갑차 등을 동원해 주변 접근을 차단했다.\n",
      "공항 가는 길목에 검문소를 늘리고, 탈레반 대원들을 추가로 투입했다.\n",
      "\n",
      "더구나, 카불공항 추가 테러 경고가 나온 상태다.\n",
      "카불 주재 미 대사관은 이날 \"구체적이고 신뢰할만한 (테러) 위협이 있다\"면서 \"카불 공항 인근에 있는 모든 미국 시민은 즉시 공항을 떠나야 한다\"고 경보령을 내렸다.\n",
      "대사관은 특히 사우스(에어포트 서클) 게이트, 내무부 신청사, 공항 북서쪽에 있는 판지시르 주유소 근처 게이트에 테러 위협이 제기됐다고 구체적으로 적시했다.\n",
      "자비훌라 무자히드 탈레반 대변인은 \"우리 대원들이 공항 내부로 들어갔고, 미군이 떠나고 나면 평화롭게 공항 통제권을 넘겨받을 준비가 돼 있다\"고 전날 말했다.\n",
      "존 커비 미 국방부 대변인은 '공항 내부로 들어갔다'는 탈레반 대변인 주장을 부인했다.\n",
      "이달 15일 탈레반이 20년만에 아프간의 정권을 다시 잡은 뒤 미군과 국제동맹군이 카불공항 내부, 탈레반이 카불공항 외부 통제권을 가졌다.\n",
      "\n",
      "즉시 아프간을 떠날 수 있는 유일한 탈출구인 '카불공항'이 곧 막히게 되자 현지인들은 육로를 통해 국경 지역에 몰리고 있다.\n",
      "아프간은 이란, 파키스탄, 투르크메니스탄, 우즈베키스탄, 타지키스탄, 중국의 신장(新疆) 위구르 자치구와 국경을 접하고 있다.\n",
      "육로를 이용해 파키스탄, 이란 등으로 탈출하는 방법이 완전히 차단되지는 않았지만, 탈레반이 주요 길목을 통제하고 있고 무역상이나 여행허가증을 가진 이들이 아니면 국경 통과가 사실상 불가능하다.\n",
      "주변국들은 이미 아프간 난민이 넘치기에 추가 난민 유입에 난색을 보인다.\n",
      "파키스탄 당국은 최근 북부 토르캄과 남서부 차만 등 아프간과 연결되는 주요 검문소의 경계와 신원 확인 절차를 크게 강화했다.\n",
      "아프간과 900㎞ 길이의 국경을 접한 이란도 접경지역 경비를 강화하고, 시스탄-바-발루치스탄주는 난민이 국경을 넘지 못하도록 철조망을 설치했다.\n",
      "\n",
      "noanoa@yna.co.kr\n",
      "저작권자(c)연합뉴스. 무단전재-재배포금지\n"
     ]
    }
   ],
   "source": [
    "contents = soup.find('div', id='harmonyContainer')\n",
    "\n",
    "for p in contents.find_all('p'):\n",
    "    print(p.get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**연습문제1) 네이버 뉴스에서 제목, 기자, 날짜, 기사내용 크롤링 하기**\n",
    "- 참고 : 네이버 뉴스는 헤더정보 넣어서 요청해야함.\n",
    "- res = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우리가 알던 ‘맨유’가 돌아왔다!\n",
      "박선우 (bergkamp@kbs.co.kr)\n",
      "2021.08.30. 오후 02:26\n",
      "2021.08.30. 오후 02:26\n",
      "\n",
      "솔샤르 맨체스터 유나이티드 감독은 이미 알고 있었다. 솔샤르 감독은 지난 27일 맨유의 캐링턴 훈련장에서 열린 기자회견에서 호날두의 맨체스터 시티 이적 관련 질문에 호날두는 맨유의 전설이라며 상황을 지켜보자고 했다. 영국의 BBC에 따르면 솔샤르는 포커페이스를 유지했지만, 호날두가 12년 만에 올드 트래퍼드로 돌아온다는 걸 알고 기자회견에 들어갔다고 한다.그날 아침 호날두가 '보스'라고 부르는 알렉스 퍼거슨 전 맨유 감독과 퍼디낸드, 에브라 등 옛 동료, 그리고 대표팀 동료이자 맨유에서 뛰는 브루누 페르난데스 등의 설득이 호날두의 마음을 돌리는데 결정적이었다고 전해진다. 맨유에서 호날두를 슈퍼스타로 조련한 퍼거슨 감독은 '유로 2016' 결승전도 호날두의 우승을 축하해 주기 위해 경기장을 찾을 정도로 막역한 사이다.호날두의 복귀를 전하는 맨유 구단의 트윗은 불과 한 시간 만에 '좋아요.' 100만 개를 넘겼다. 인스타그램에서도 역대 스포츠 구단 게시물 가운데 최다인 126만 명이 '좋아요'를 눌렀다. 맨유 공식 홈페이지는 접속이 안 될 정도였고, 구단 주가는 8%나 올라갔다.■'호날두 효과' 맨유, 단숨에 우승 후보!유럽 여름 이적 시장이 이렇게 뜨거운 적이 있었나? 메시가 파리 생제르맹 유니폼을 입고 오늘(30일) 데뷔전을 치렀다. 메시에 이어 호날두의 맨유 복귀전도 보름 안에 열릴 가능성이 크다. 호날두는 포르투갈의 월드컵 예선에 출전한 뒤 오는 11일 '꿈의 구장' 올드 트래퍼드에서 열릴 뉴캐슬전에 나설 전망이다. 공교롭게도 호날두는 맨유 시절 뉴캐슬과의 마지막 대결에서 해트트릭을 작성하며 6대 0 대승을 이끈 기분 좋은 기억도 있다.ESPN은 호날두의 가세로 맨유 스쿼드의 깊이가 엄청나졌다고 평가했다. 이적 시장 마감일까지 지켜봐야겠지만, 최전방에는 호날두와 카바니, 개막 후 3경기 연속 골 맛을 본 '무서운 10대' 그린우드가 설 수 있다. 왼쪽 측면에 래시포드, 오른쪽 측면에는 이적생 산초가 버틴다. 2선의 브루누 페르난데스와 포그바, 맥토미니까지 공격진은 드림팀에 가깝다. 매과이어와 바란의 중앙 수비수 조합은 리그 최고 수준이며 기량이 급성장한 루크 쇼와 완 비사카가 측면 수비수로 나선다. 골문은 데 헤아가 지킨다.■ 우리가 알던 '맨유'가 돌아왔다!그야말로 우리가 과거에 알던 맨유의 모습으로 돌아간 느낌이다. 퍼거슨이 이끌던 전성기의 위용을 되찾을지도 관심이다. 맨유는 오늘 새벽(한국 시간) 황희찬이 이적한 울버햄프턴을 상대로 1대 0으로 승리하며 프리미어리그 원정 경기 최다 연속 무패(28경기, 18승 10무) 기록까지 경신했다. 맨유의 원정 팬들은 아직 그라운드에 나서지도 않은 '호날두 만세'를 외쳤다고 한다.손흥민 덕분에 3연승을 달린 토트넘이 1위, 토트넘의 북런던 라이벌 아스널이 최하위인 20위에 자리한 건 프리미어리그 역사상 처음이다. 호날두의 이적으로 점점 흥미로워지는 프리미어리그, 지난 시즌 챔피언 맨시티와 맨유가 벌일 이웃끼리의 자존심 대결도 축구 팬들의 마음을 설레게 할 전망이다.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://sports.news.naver.com/news?oid=056&aid=0011110649'\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "title = soup.find('h4', class_=\"title\")\n",
    "print(title.get_text())\n",
    "\n",
    "arthor = soup.find('p', class_=\"byline\")\n",
    "print(arthor.get_text())\n",
    "\n",
    "date = soup.find('div', class_=\"info\")\n",
    "\n",
    "for day in date.find_all('span'):\n",
    "    print(day.get_text()[5:])\n",
    "    \n",
    "articles = soup.find('div', id=\"newsEndContents\")\n",
    "print(articles.get_text().split('\\n')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "백신 맞고 백혈병 판정 잇따라…이번엔 태권도 관장\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'뉴시스코로나19 백신을 접종받은 뒤 백혈병 진단을 받았다는 내용의 국민청원이 잇따르고 있다.27일 청와대 국민청원 게시판에는 ‘건강한 30대 중반 태권도 관장 저희 형이 얀센 백신 접종 후 급성 골수성 백혈병 진단을 받았습니다’라는 제목의 청원이 게재됐다.청원인 A씨는 “감기 한번 크게 걸린 적 없는 형이 얀센 백신을 맞고 급성 골수성 백혈병 진단을 받았다”고 글을 시작했다.청원에 따르면 A씨의 형인 B씨는 대전에서 태권도 도장을 운영하고 있다. 아이들을 가르치던 B씨는 ‘예비군에게 얀센 백신을 접종한다’는 말에 서둘러 접종을 마쳤다. 하지만 접종 후 몸 상태가 좋지 않아 보건소에 이의 신청을 했다. 동네 병원에서는 피검사 결과가 좋지 않다며 대학병원에서 정밀검사를 받으라고 진단했다.청와대 국민청원 캡처A씨는 “대학병원에서 골수검사를 받은 결과 급성 골수성 백혈병이라는 진단을 받았다”며 “TV로만 보던 (백신) 부작용이 우리 가족에게, 내 형한테 일어날 줄은 상상도 못했다”고 토로했다.이어 “평생 운동하고 건강하던 형이 이렇게 된 현실을 인정할 수 없다”며 “지금은 조카 얼굴을 보는 것조차 힘들어할 정도로 체력이 많이 떨어진 상태”라고 전했다.A씨는 “형이 잘못한 건 100% 인정되지 않은 백신을 생업과 가족을 위해 너무 급하게 맞은 걸까요”라고 물었다. 또 “우리 말고도 많은 분들이 백신으로 인해 급성 백혈병 진단 등 부작용을 겪고 있다. 하지만 이런 일들이 묻히고 있다”고 말했다.그러면서 “정부가 백신과 관련된 부작용과 피해자 가족에 대해 적합한 보상을 해달라”고 호소했다.이 청원은 사전 동의 기준인 100명을 넘어 관리자가 공개 여부를 검토 중이다. 30일 오전 9시 기준 5600명 이상의 동의를 받았다.코로나19 백신 접종 후 급성 골수성 백혈병 진단을 받았다는 사례는 이번이 처음이 아니다.최근 대구에 체육교사로 근무 중이던 30대 예비신랑이 화이자 백신 1차 접종 후 백혈병 판정을 받았다는 청원글이 올라왔다. 청원인은 “평소 술, 담배를 하지 않고 운동을 꾸준히 해오며 크고 작은 질병이 없던 사람이었다”며 “8월 22일 잇몸치료를 받고 지혈이 되지 않아 대학병원 응급실에 갔다. 응급실에 도착한 후 미열이 나서 코로나19 의심 환자 격리실에서 혈액검사를 했고 몇 시간 후에 혈액암이 의심돼 입원을 권장했으며 며칠간의 추가적인 검사 결과 급성 골수성 백혈병 진단을 받았다”고 했다.청원인은 “평소 무척이나 건강했던 사람이라 검사 결과가 믿기지 않았다”며 “저를 포함해 많은 국민이 부작용 없이 일상을 보내고 있지만, 한편으로는 백신 접종 후 갑작스러운 사망과 급성 백혈병 진단 등 크고 작은 부작용에 고통받고 있을 국민이 걱정됐다”고 적었다. 이어 “정부를 믿는 국민에게 백신에 대한 책임감을 가지고, 부작용 사례에 있어서 부정만 할 것이 아니라 인과관계를 증명해 더는 저희와 같은 억울한 사례가 없길 원한다”고 호소했다.이외에도 지난 17일 화이자 백신을 맞은 20대 군인이, 24일 아스트라제네카 백신을 접종받은 60대 여성이 급성 골수성 백혈병 진단을 받았다는 내용의 청원이 올라와 백신 부작용에 대한 진상 규명을 촉구했다.최민우 기자 cmwoo11@kmib.co.kr'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://news.kmib.co.kr/article/view.asp?arcid=0016216715&code=61121111&sid1=soc&cp=nv2'\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(res.content.decode('euc-kr', 'replace'), 'lxml')\n",
    "\n",
    "title = soup.find('div', class_=\"nwsti\")\n",
    "print(title.find('h3').get_text())\n",
    "\n",
    "articles = soup.find('div', id=\"articleBody\")\n",
    "articles.get_text().split('\\n')[2].split('\\r')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 실전연습(네이버 웹툰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>네이버 만화 &gt; 요일별  웹툰 &gt; 전체웹툰</title>\n",
      "네이버 만화 > 요일별  웹툰 > 전체웹툰\n",
      "<a href=\"#menu\" onclick=\"document.getElementById('menu').tabIndex=-1;document.getElementById('menu').focus();return false;\"><span>메인 메뉴로 바로가기</span></a>\n",
      "{'href': '#menu', 'onclick': \"document.getElementById('menu').tabIndex=-1;document.getElementById('menu').focus();return false;\"}\n",
      "#menu\n"
     ]
    }
   ],
   "source": [
    "#html문서를 lxml파서를 통해서 beautiful 객체로 만들기. soup는 모든걸 가지고 있다.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://comic.naver.com/webtoon/weekday.nhn\"\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "print(soup.title)\n",
    "print(soup.title.get_text())\n",
    "print(soup.a)\n",
    "print(soup.a.attrs)\n",
    "print(soup.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. 웹툰올리기 tag 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"Nbtn_upload\" href=\"/mypage/myActivity\" onclick=\"nclk_v2(event,'olk.upload');\">웹툰 올리기</a>\n",
      "<a class=\"Nbtn_upload\" href=\"/mypage/myActivity\" onclick=\"nclk_v2(event,'olk.upload');\">웹툰 올리기</a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('a', attrs={'class':'Nbtn_upload'}))\n",
    "print(soup.find(attrs={'class':'Nbtn_upload'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. 인기 급상승 만화 tag 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"rank01\">\n",
      "<a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>\n",
      "<span class=\"rankBox\">\n",
      "<img alt=\"변동없음\" height=\"10\" src=\"https://ssl.pstatic.net/static/comic/images/migration/common/arrow_no.gif\" title=\"변동없음\" width=\"7\"/> 0\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t</span>\n",
      "</li>\n",
      "\n",
      "<a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>\n",
      "\n",
      "여신강림-172화\n",
      "\n",
      "https://comic.naver.com/webtoon/detail?titleId=703846&no=177\n"
     ]
    }
   ],
   "source": [
    "rank1 = soup.find('li', class_=\"rank01\")\n",
    "print(rank1)\n",
    "print()\n",
    "print(rank1.a)\n",
    "print()\n",
    "print(rank1.a.get_text())\n",
    "print()\n",
    "print('https://comic.naver.com'+rank1.a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인기 급상승 만화 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여신강림-172화\n",
      "한림체육관-66화\n",
      "사신소년-112화 ㅆ발\n",
      "한림체육관-66화\n"
     ]
    }
   ],
   "source": [
    "rank1 = soup.find('li', attrs={'class':\"rank01\"})\n",
    "print(rank1.a.get_text())\n",
    "\n",
    "rank2 = rank1.next_sibling.next_sibling\n",
    "print(rank2.a.get_text())\n",
    "\n",
    "rank3 = rank2.next_sibling.next_sibling\n",
    "print(rank3.a.get_text())\n",
    "\n",
    "rank2 = rank3.previous_sibling.previous_sibling\n",
    "print(rank2.a.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_next_sibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한림체육관-66화\n",
      "사신소년-112화 ㅆ발\n"
     ]
    }
   ],
   "source": [
    "rank2 = rank1.find_next_sibling('li')\n",
    "print(rank2.a.get_text())\n",
    "\n",
    "rank3 = rank2.find_next_sibling('li')\n",
    "print(rank3.a.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_next_siblings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여신강림-172화\n",
      "한림체육관-66화\n",
      "사신소년-112화 ㅆ발\n",
      "중증외상센터 : 골든 아워-2부 15화 : 알릴 건 알려야지\n",
      "하루만 네가 되고 싶어-88. 삼자대면(2)\n",
      "랜덤채팅의 그녀!-197. 내로남불\n",
      "달콤살벌한 부부-52화\n",
      "엽총소년-27화\n",
      "용사가 돌아왔다-13화 용사들(1)\n",
      "신도림-시즌2 93. 그릇\n"
     ]
    }
   ],
   "source": [
    "# iterable\n",
    "rank1 = soup.find('li', attrs={'class':\"rank01\"})\n",
    "print(rank1.a.get_text())\n",
    "\n",
    "ranks = rank1.find_next_siblings('li')\n",
    "for rank in ranks:\n",
    "    print(rank.a.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = soup.find('ol', attrs={'class':'asideBoxRank', 'id':\"realTimeRankFavorite\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/webtoon/detail?titleId=703846&amp;no=177\" onclick=\"nclk_v2(event,'rnk*p.cont','703846','1')\" title=\"여신강림-172화\">여신강림-172화</a>\n"
     ]
    }
   ],
   "source": [
    "# 태그 가져오는 법\n",
    "webtoon = soup.find('a', text='여신강림-172화')\n",
    "print(webtoon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. 네이버 웹툰 전체 목록 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "참교육\n",
      "신의 탑\n",
      "뷰티풀 군바리\n",
      "윈드브레이커\n",
      "팔이피플\n",
      "소녀의 세계\n",
      "장씨세가 호위무사\n",
      "백수세끼\n",
      "파이게임\n",
      "앵무살수\n",
      "만렙돌파\n",
      "삼매경\n",
      "잔불의 기사\n",
      "요리GO\n",
      "더블클릭\n",
      "약초마을 연쇄살초사건\n",
      "유일무이 로맨스\n",
      "칼가는 소녀\n",
      "바퀴\n",
      "히어로메이커\n",
      "결혼생활 그림일기\n",
      "물어보는 사이\n",
      "꼬리잡기\n",
      "영앤리치가 아니야!\n",
      "오늘의 순정망화\n",
      "ㅋㄷㅋㄷ만화\n",
      "리턴 투 플레이어\n",
      "평범한 8반\n",
      "아, 쫌 참으세요 영주님!\n",
      "아는 여자애\n",
      "수영만화일기\n",
      "황제와의 하룻밤\n",
      "장난감\n",
      "홍천기\n",
      "꿈의 기업\n",
      "순정말고 순종\n",
      "똑 닮은 딸\n",
      "최후의 금빛아이\n",
      "하루의 하루\n",
      "와이키키 뱀파이어\n",
      "야생천사 보호구역\n",
      "모스크바의 여명\n",
      "착한건 돈이된다\n",
      "사랑의 헌옷수거함\n",
      "선배, 그 립스틱 바르지 마요\n",
      "왕따협상\n",
      "이중첩자\n",
      "원하는 건 너 하나\n",
      "또다시, 계약 부부\n",
      "백호랑\n",
      "라서드\n",
      "마지막 지수\n",
      "사막에 핀 달\n",
      "드로잉 레시피\n",
      "중독연구소\n",
      "살아간다\n",
      "이탄국의 자청비\n",
      "모락모락 왕세자님\n",
      "그림자 신부\n",
      "바로 보지 않는\n",
      "개밥 먹는 남자\n",
      "헬로맨스\n",
      "보살님이 캐리해!\n",
      "오로지 오로라\n",
      "트리거\n",
      "기사님을 지켜줘\n",
      "여신강림\n",
      "용사가 돌아왔다\n",
      "덴큐\n",
      "한림체육관\n",
      "엽총소년\n",
      "하루만 네가 되고 싶어\n",
      "사신소년\n",
      "중증외상센터 : 골든 아워\n",
      "랜덤채팅의 그녀!\n",
      "신도림\n",
      "니나의 마법서랍\n",
      "헬58\n",
      "달콤살벌한 부부\n",
      "호랑이 들어와요\n",
      "천마는 평범하게 살 수 없다\n",
      "집이 없어\n",
      "오피스 누나 이야기\n",
      "원주민 공포만화\n",
      "몬스터\n",
      "블랙 위도우\n",
      "윌유메리미\n",
      "삼국지톡\n",
      "아이레\n",
      "위아더좀비\n",
      "하우스키퍼\n",
      "빌런투킬\n",
      "이상형은 아닙니다\n",
      "견우와 선녀\n",
      "오늘의 순정망화\n",
      "플레이, 플리\n",
      "용왕님의 셰프가 되었습니다\n",
      "기계증식증\n",
      "교환학생\n",
      "아이즈\n",
      "3cm 헌터\n",
      "제로게임\n",
      "정년이\n",
      "성인초딩\n",
      "올가미\n",
      "빅맨\n",
      "은주의 방 2~3부\n",
      "악인\n",
      "나타나주세요!\n",
      "연우의 순정\n",
      "나는 어디에나 있다\n",
      "열녀박씨 계약결혼뎐\n",
      "다꾸남\n",
      "숲속의 담\n",
      "나의 플랏메이트\n",
      "오파츠\n",
      "태시트\n",
      "조선홍보대행사 조대박\n",
      "그녀석 정복기\n",
      "안식의 밤\n",
      "대신 심부름을 해다오\n",
      "자판귀\n",
      "급식러너\n",
      "연애는 전쟁!\n",
      "완벽한 가족\n",
      "언메이크\n",
      "고등매직\n",
      "프린스 메이커\n",
      "지원이들\n",
      "풋내기들\n",
      "NG불가\n",
      "하나in세인\n",
      "피로만땅\n",
      "인문학적 감수성\n",
      "찐:종합게임동아리\n",
      "헬퍼 2 : 킬베로스\n",
      "전지적 독자 시점\n",
      "조조코믹스\n",
      "무서운게 딱좋아!\n",
      "모죠의 일지\n",
      "캐슬\n",
      "튜토리얼 탑의 고인물\n",
      "화산귀환\n",
      "급식아빠\n",
      "여주실격!\n",
      "남주의 첫날밤을 가져버렸다\n",
      "노곤하개\n",
      "세상은 돈과 권력\n",
      "66666년 만에 환생한 흑마법사\n",
      "일렉시드\n",
      "블랙홀과 3만원\n",
      "연놈\n",
      "닥터앤닥터 육아일기\n",
      "나쁜사람\n",
      "고삼무쌍\n",
      "마른 가지에 바람처럼\n",
      "엔딩 후 서브남을 주웠다\n",
      "빌드업\n",
      "원수를 사랑하라\n",
      "괴물공작의 딸\n",
      "관종교장\n",
      "밤낚시\n",
      "하렘의 남자들\n",
      "판타지 여동생!\n",
      "귀곡의 문\n",
      "사상최강\n",
      "언덕 위의 제임스\n",
      "방탈출\n",
      "아도나이\n",
      "마녀와 용의 신혼일기\n",
      "오징어도 사랑이 되나요?\n",
      "새벽 두 시의 신데렐라\n",
      "얼굴천재\n",
      "로어 올림푸스\n",
      "화가 살리에르\n",
      "럭키언럭키\n",
      "칼부림\n",
      "반귀\n",
      "범이올시다!\n",
      "속보입니다\n",
      "수요웹툰의 나강림\n",
      "반짝반짝 작은 눈\n",
      "사랑과 평강의 온달!\n",
      "무용과 남학생\n",
      "여우담:스윗싱가포르\n",
      "뱀은 꽃을 먹는가\n",
      "웰컴 온보드\n",
      "스캔들\n",
      "해귀\n",
      "기억흔적\n",
      "신선비\n",
      "천도\n",
      "저승사자 출입금지\n",
      "구주\n",
      "수상한 비밀상담부\n",
      "내 룸메이트는 마네킹\n",
      "나의 계절\n",
      "시효완성\n",
      "더 복서\n",
      "연애혁명\n",
      "기기괴괴\n",
      "나노마신\n",
      "이두나!\n",
      "묵시의 인플루언서\n",
      "화이트 블러드\n",
      "포식동물\n",
      "노답소녀\n",
      "정글쥬스\n",
      "겟백\n",
      "오빠세끼\n",
      "무사만리행\n",
      "하드캐리\n",
      "마왕까지 한 걸음\n",
      "던전 씹어먹는 아티팩트\n",
      "트롤트랩\n",
      "신비\n",
      "흑막 여주가 날 새엄마로 만들려고 해\n",
      "쿠베라\n",
      "최강전설 강해효\n",
      "별을 삼킨 너에게\n",
      "아빠같은 남자\n",
      "뜨거운 양철지붕 위의 고양이\n",
      "시에라\n",
      "선의의 경쟁\n",
      "오늘의 순정망화\n",
      "어느날 네가 떠올라!\n",
      "완벽한 결혼의 정석\n",
      "폭탄주먹 변대장\n",
      "마법사랑해\n",
      "만물의 영장\n",
      "안개무덤\n",
      "네가 죽기를 바랄 때가 있었다\n",
      "불편한 관계\n",
      "수영만화일기\n",
      "꽃만 키우는데 너무강함\n",
      "길티액스\n",
      "시월드 판타지\n",
      "마계인섬\n",
      "롤랑롤랑\n",
      "로그아웃\n",
      "THE 런웨이\n",
      "그 개, 만두\n",
      "성스러운 아이돌\n",
      "달의 요람\n",
      "그 황제가 시곗바늘을 되돌린 사연\n",
      "루커피쳐\n",
      "겟라이프\n",
      "야만의 시대\n",
      "어차피 남편은!\n",
      "집사레인저\n",
      "소년의 기록\n",
      "유리와 유리와 유리\n",
      "돌아온 여기사\n",
      "온새미로\n",
      "혼모노트\n",
      "온실 속 화초\n",
      "평범한 낙원\n",
      "카루나\n",
      "밤하늘에 구름운\n",
      "멸망X초이스\n",
      "헬프미\n",
      "보물과 괴물의 도시\n",
      "모어 라이프\n",
      "바른탕진 프로젝트\n",
      "외모지상주의\n",
      "나 혼자 만렙 뉴비\n",
      "유미의 세포들 외전 : 프로 직장인\n",
      "갓 오브 하이스쿨\n",
      "데드퀸\n",
      "1초\n",
      "죽지 않으려면\n",
      "개를 낳았다\n",
      "광마회귀\n",
      "서울역 드루이드\n",
      "식인귀\n",
      "말년용사\n",
      "세기말 풋사과 보습학원\n",
      "더 게이머\n",
      "여성전용헬스장 진달래짐\n",
      "블랙 위도우\n",
      "구남친이 내게 반했다\n",
      "상남자\n",
      "걸어서 30분\n",
      "플레이어\n",
      "삼국지톡\n",
      "그들이 사귀는 세상\n",
      "히어로 킬러\n",
      "환상의 용\n",
      "A.I. 닥터\n",
      "빨간맛 로맨스\n",
      "가슴털 로망스\n",
      "여우놀이\n",
      "역대급 영지 설계사\n",
      "감자마을\n",
      "그 기사가 레이디로 사는 법\n",
      "네버엔딩달링\n",
      "미친 후작을 길들이고 말았다\n",
      "엽사:요괴사냥꾼\n",
      "버그: 스티그마\n",
      "쌈빡\n",
      "피와 나비\n",
      "로판 빙의 만화\n",
      "후덜덜덜 남극전자\n",
      "인피니티\n",
      "다름이 아니라\n",
      "닥터 프로스트 시즌 3~4\n",
      "주님, 악마가 되게 해주세요!\n",
      "사람의 조각\n",
      "악몽일기\n",
      "너의 미소가 함정\n",
      "몽홀\n",
      "도무지 그애는\n",
      "거래\n",
      "태권보이\n",
      "방과후 선녀\n",
      "킬러방 : 퍼스트 킬\n",
      "아찔한 전남편\n",
      "트럼프\n",
      "빨리감기\n",
      "썸내일\n",
      "팬시X팬시\n",
      "백년게임\n",
      "꽃 피우는 남자\n",
      "나쁜 쪽으로\n",
      "구주의 시간\n",
      "찬란하지 않아도 괜찮아, 새벽\n",
      "진짜 정말 맹세코 좋아해\n",
      "행운을 빌어요, 용사님!\n",
      "합법해적 파르페\n",
      "강림전기 개정기\n",
      "매지컬 메디컬\n",
      "도깨비 고개\n",
      "조조코믹스\n",
      "호랑이형님\n",
      "프리드로우\n",
      "스퍼맨 : 전하지 못한 이야기\n",
      "취사병 전설이 되다\n",
      "모죠의 일지\n",
      "광장\n",
      "망나니 소교주로 환생했다\n",
      "최면학교\n",
      "니나의 마법서랍\n",
      "노곤하개\n",
      "욕망일기\n",
      "힙한남자\n",
      "스터디그룹\n",
      "나이트런\n",
      "윌유메리미\n",
      "나를 바꿔줘\n",
      "은둔코인\n",
      "반드시 해피엔딩\n",
      "어글리후드\n",
      "탑코너\n",
      "좀비 파이트\n",
      "피라미드 게임\n",
      "청춘 블라썸\n",
      "지구식 구원자 전형\n",
      "지옥급식\n",
      "태백 : 튜토리얼 맨\n",
      "나태 공자, 노력 천재 되다\n",
      "메트로헌터\n",
      "아홉수 우리들\n",
      "감 비서가 고장났다\n",
      "공유몽\n",
      "왕년엔 용사님\n",
      "웰캄투실버라이프\n",
      "먹이\n",
      "단편.zip\n",
      "남편을 만렙으로 키우려 합니다\n",
      "남자주인공의 여자사람친구입니다\n",
      "군주\n",
      "왕세자 입학도\n",
      "내게 필요한 NO맨스\n",
      "함부로 대해줘\n",
      "중매쟁이 아가 황녀님\n",
      "저무는 해, 시린 눈\n",
      "같은 학교 친구\n",
      "동네몬스터\n",
      "율리\n",
      "팔려 온 신부\n",
      "압락사스\n",
      "키스 식스 센스\n",
      "나를 길들여 봐, 차비서\n",
      "오늘부터 천생연분\n",
      "모두 너였다\n",
      "더 나우\n",
      "좋은데 어떡해\n",
      "주욱 같은 하루\n",
      "도사 가온\n",
      "안녕, 이바다씨\n",
      "아가사\n",
      "후아유!\n",
      "2-3승강장\n",
      "아침을 지나 밤으로\n",
      "인간졸업\n",
      "손 잡아 볼래?\n",
      "먹지마세요\n",
      "광해의 연인\n",
      "싸움독학\n",
      "수희0(tngmlek0)\n",
      "무서운게 딱좋아!\n",
      "이번 생도 잘 부탁해\n",
      "열렙전사\n",
      "약한영웅\n",
      "입학용병\n",
      "투신전생기\n",
      "어느날 갑자기 서울은\n",
      "닥터앤닥터 육아일기\n",
      "곱게 키웠더니, 짐승\n",
      "소녀재판\n",
      "경자 전성시대\n",
      "천하제일인\n",
      "오로지 너를 이기고 싶어\n",
      "테러대부활\n",
      "나만 보여!\n",
      "살아남은 로맨스\n",
      "내일\n",
      "마법스크롤 상인 지오\n",
      "사실 마법이었던 거임\n",
      "천치전능\n",
      "별이삼샵\n",
      "판사 이한영\n",
      "구름이 피워낸 꽃\n",
      "벚꽃이 흩날릴 무렵\n",
      "합격시켜주세용\n",
      "AI가 세상을 지배한다면\n",
      "로어 올림푸스\n",
      "예쁜 사나이\n",
      "강남도깨비\n",
      "취향 소개소\n",
      "혀로 만난 사이\n",
      "학교정벌\n",
      "동생친구\n",
      "평행도시\n",
      "생존로그\n",
      "아르세니아의 마법사\n",
      "거래하실래요?\n",
      "불순물\n",
      "몸이 바뀌는 사정\n",
      "전설의 화석\n",
      "결혼까지 망상했어!\n",
      "잉여특공대\n",
      "다시 또 봄\n",
      "짝사랑의 유서\n",
      "데빌샷\n",
      "사람은 고쳐 쓰는 게 아니야!\n",
      "황제에게 하트를 심어주세요\n",
      "패션쇼\n",
      "굿 리스너\n",
      "조선여우스캔들\n",
      "가짜인간\n",
      "소녀 해미\n",
      "독신마법사 기숙아파트\n",
      "라커, 오프너\n",
      "위험한 신입사원\n",
      "오늘 밤만 재워줘\n",
      "호수의 인어\n",
      "제타\n",
      "데이즈\n",
      "푸른불꽃\n",
      "샤인 스타\n",
      "호시탐탐\n"
     ]
    }
   ],
   "source": [
    "# 네이버 웹툰 전체 목록 가져오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =\"https://comic.naver.com/webtoon/weekday.nhn\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "cartoons = soup.find_all('a', class_='title')\n",
    "\n",
    "for cartoon in cartoons:\n",
    "    print(cartoon.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. 특정 웹툰정보 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172화 https://comic.naver.com/webtoon/detail?titleId=703846&no=177&weekday=tue\n",
      "171화 https://comic.naver.com/webtoon/detail?titleId=703846&no=176&weekday=tue\n",
      "170화 https://comic.naver.com/webtoon/detail?titleId=703846&no=175&weekday=tue\n",
      "169화 https://comic.naver.com/webtoon/detail?titleId=703846&no=174&weekday=tue\n",
      "168화 https://comic.naver.com/webtoon/detail?titleId=703846&no=173&weekday=tue\n",
      "167화 https://comic.naver.com/webtoon/detail?titleId=703846&no=172&weekday=tue\n",
      "166화 https://comic.naver.com/webtoon/detail?titleId=703846&no=171&weekday=tue\n",
      "165화 https://comic.naver.com/webtoon/detail?titleId=703846&no=170&weekday=tue\n",
      "164화 https://comic.naver.com/webtoon/detail?titleId=703846&no=169&weekday=tue\n",
      "163화 https://comic.naver.com/webtoon/detail?titleId=703846&no=168&weekday=tue\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 기본 웹크롤링\n",
    "url = 'https://comic.naver.com/webtoon/list?titleId=703846&weekday=tue'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "cartoons = soup.find_all('td', attrs={'class':\"title\"})\n",
    "# rink = 'https://comic.naver.com'+cartoons[0].a['href']\n",
    "# print(rink)\n",
    "# print(cartoons[0])\n",
    "rink = 'https://comic.naver.com'\n",
    "\n",
    "for cartoon in cartoons:\n",
    "    print(cartoon.a.get_text(), rink+cartoon.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.20\n",
      "8.17\n",
      "7.65\n",
      "6.39\n",
      "8.17\n",
      "8.47\n",
      "8.34\n",
      "9.45\n",
      "9.55\n",
      "8.78\n",
      "전체점수: 84.17\n",
      "전체별점: 8.417\n"
     ]
    }
   ],
   "source": [
    "points = soup.find_all('div', class_='rating_type')\n",
    "\n",
    "total_point = 0\n",
    "for point in points:\n",
    "    rate1 = point.find('strong').get_text()\n",
    "    rate2 = point.strong.get_text()\n",
    "    print(rate2)\n",
    "    total_point += float(rate1)\n",
    "    \n",
    "print('전체점수:', total_point)\n",
    "print('전체별점:', total_point/len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**연습문제2) 네이버 웹툰 중에서 좋아하는 웹툰 정보(회차/링크/별점) 가지고 오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://comic.naver.com/webtoon/list?titleId=758037&weekday=mon'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여신강림\n",
      "\t\t\n",
      "172화 https://comic.naver.com/webtoon/detail?titleId=703846&no=177&weekday=tue 9.19\n",
      "171화 https://comic.naver.com/webtoon/detail?titleId=703846&no=176&weekday=tue 8.16\n",
      "170화 https://comic.naver.com/webtoon/detail?titleId=703846&no=175&weekday=tue 7.65\n",
      "169화 https://comic.naver.com/webtoon/detail?titleId=703846&no=174&weekday=tue 6.39\n",
      "168화 https://comic.naver.com/webtoon/detail?titleId=703846&no=173&weekday=tue 8.17\n",
      "167화 https://comic.naver.com/webtoon/detail?titleId=703846&no=172&weekday=tue 8.47\n",
      "166화 https://comic.naver.com/webtoon/detail?titleId=703846&no=171&weekday=tue 8.34\n",
      "165화 https://comic.naver.com/webtoon/detail?titleId=703846&no=170&weekday=tue 9.45\n",
      "164화 https://comic.naver.com/webtoon/detail?titleId=703846&no=169&weekday=tue 9.55\n",
      "163화 https://comic.naver.com/webtoon/detail?titleId=703846&no=168&weekday=tue 8.78\n"
     ]
    }
   ],
   "source": [
    "cartoons = soup.find_all('div', class_='rating_type')\n",
    "\n",
    "point = []\n",
    "\n",
    "for cartoon in cartoons:\n",
    "    point.append(cartoon.find('strong').get_text())\n",
    "\n",
    "title = soup.find('div', class_='detail')\n",
    "print(title.find('h2').get_text().strip()[:7])\n",
    "\n",
    "cartoons = soup.find_all('td', class_='title')\n",
    "\n",
    "for idx, cartoon in enumerate(cartoons):\n",
    "    cartoons = soup.find_all('td', class_='title')\n",
    "    title = cartoon.a.get_text()\n",
    "    link = 'https://comic.naver.com'+cartoon.a['href']\n",
    "    print(title, link, point[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
